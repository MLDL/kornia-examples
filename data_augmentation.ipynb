{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_augmentation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arraiyopensource/kornia-examples/blob/master/data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAAeyk5IA1k-",
        "colab_type": "text"
      },
      "source": [
        "# Data augmentation on the GPU\n",
        "\n",
        "In this data you learn how to use `kornia` modules in order to perform the data augmentatio on the GPU in batch mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15809beqBIDj",
        "colab_type": "text"
      },
      "source": [
        "## 1. Create a dummy data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHdQxCUxBjF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA3jWZrJBMa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from: https://gist.github.com/edgarriba/a781de516c508826f79568d08598efdb\n",
        "\n",
        "class DummyDataset(Dataset):\n",
        "    def __init__(self, data_root=None):\n",
        "        self.data_root = data_root\n",
        "        self.data_index = self.build_index(self.data_root)\n",
        "\n",
        "    def build_index(self, data_root):\n",
        "        return range(10)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get data sample\n",
        "        sample = self.data_index[idx]\n",
        "\n",
        "        # load data, NOTE: modify by cv2.imread(...)\n",
        "        image = torch.rand(3, 240, 320)\n",
        "        label = torch.rand(1, 240, 320)\n",
        "        return dict(images=image, labels=label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMW50yR_CbvV",
        "colab_type": "text"
      },
      "source": [
        "## 2. Define the data augmentation operations\n",
        "\n",
        "Thanks to the `kornia` design all the operators can be placed inside inside a `nn.Sequential`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glikzf3YDAfX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "861d97a9-cf15-4b73-8e61-93b751ae11f9"
      },
      "source": [
        "!pip install git+https://github.com/arraiyopensource/kornia\n",
        "import kornia"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/arraiyopensource/kornia\n",
            "  Cloning https://github.com/arraiyopensource/kornia to /tmp/pip-req-build-2opte954\n",
            "  Running command git clone -q https://github.com/arraiyopensource/kornia /tmp/pip-req-build-2opte954\n",
            "Requirement already satisfied (use --upgrade to upgrade): kornia==0.1.2+4067336 from git+https://github.com/arraiyopensource/kornia in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from kornia==0.1.2+4067336) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->kornia==0.1.2+4067336) (1.16.5)\n",
            "Building wheels for collected packages: kornia\n",
            "  Building wheel for kornia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kornia: filename=kornia-0.1.2+4067336-py2.py3-none-any.whl size=110458 sha256=ff8cc4afc554f3ef21031bbacec56adc4c46ca60f8df1e8c99c484f38be7f401\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vdn8wu2n/wheels/a0/47/86/854e2f9a801b368f296cb25f167cbd56aa805f974b15421a67\n",
            "Successfully built kornia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcCfxxPfDSok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = nn.Sequential(\n",
        "    kornia.color.AdjustBrightness(0.5),\n",
        "    kornia.color.AdjustGamma(gamma=2.),\n",
        "    kornia.color.AdjustContrast(0.7),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okVQosxlByqq",
        "colab_type": "text"
      },
      "source": [
        "## 3. Run the dataset and perform the data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9wNZo5qB5HL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "9acf64d8-46e7-48e7-88a2-9d28fcce114c"
      },
      "source": [
        "# check if cuda exists\n",
        "if torch.cuda.is_available:\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print(f\"Runing with device: {device}\")\n",
        "  \n",
        "# create the dataloader\n",
        "dataset = DummyDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# get samples and perform the data augmentation\n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    images = sample_batched['images'].to(device)\n",
        "    labels = sample_batched['labels'].to(device)\n",
        "    \n",
        "    # perform the transforms\n",
        "    images = transform(images)\n",
        "    labels = transform(labels)\n",
        "    \n",
        "    print(f\"Iteration: {i_batch} Image shape: {images.shape}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Runing with device: cuda\n",
            "Iteration: 0 Image shape: torch.Size([4, 3, 240, 320])\n",
            "Iteration: 1 Image shape: torch.Size([4, 3, 240, 320])\n",
            "Iteration: 2 Image shape: torch.Size([2, 3, 240, 320])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}